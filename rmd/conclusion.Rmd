# Conclusion

## Issues and improvements

The target distribution in the data is rather skewed, making it is rather difficult to learn. In that work we chose Weibull to model it, although it would be interesting to investigate the performance of Exponential (which has properties similar to the Gamma distribution, but a survival function like a Weibull), or a Cox regression.

Another issue was the relatively low $n_\text{eff}$ of the hierarchical model, and one critically low $n_\text{eff} / N$ statistic. In certain situations, the group-level parameters do not constrain the hierarchical distribution closely enough. This can occur when we either have many groups or high variance between the groups. In order to make hierarchical model sampling more efficient and to improve effective sample size metrics, we could employ a so-called _non-centered parameterisation_, where we replace the parameterisation of 
```
parameters {
  // GLM parameters
  matrix[M, J] beta;            // regressors weights for different institutions
  real<lower=0> alpha;          // shape parameter
  ...
}
model {
  // hyperpriors
  mu_beta ~ std_normal();
  sigma_beta ~ gamma(1, 1);
  // prior over regressor and shape parameters
  for (j in 1:J) {
    beta[j] ~ normal(mu_beta, sigma_beta);
  }
  ...
```
to
```
parameters {
  // hyperparameters
  real mu_beta;
  real<lower=0> sigma_beta;
  // GLM parameters
  matrix[M, J] beta_unif;       // non-centered parameterisation regressors
  real<lower=0> alpha;          // shape parameter
  ...
}
transformed parameters {
  vector[M] beta[J];            // regressors weights for different institutions
  // implies: beta ~ normal(mu_beta, sigma_beta)
  for (j in 1:J) {
    beta[j] = mu_beta + sigma_beta * beta_unif[j];
  }
  ...
}
model {
  // hyperpriors
  mu_beta ~ std_normal();
  sigma_beta ~ gamma(1, 1);
  // prior over regressor and shape parameters (non-centered parameterisation)
  for (j in 1:J) {
    beta_unif[j] ~ std_normal();
  }
  ...
```
so that our `beta`, `mu_beta` and `sigma_beta` are less correlated with our posterior, and thus increasing the effective sample size, as is shown in @betancourt2013hamiltonian. This reparameterisation, however, will likely not significantly improve $n_\text{eff}$ of the hierarchical model, as we have neither too many groups nor too many data. A Stan implementation is available at @git for further interest.

Some warnings were returned relating to low Bayesian Fraction of Missing Information estimates. @betancourt2013hamiltonian suggests that this is indicative of an improper adaptation phase in the Markov Chains, and thus results in an inefficient exploration of the posterior distribution. Much like the treedepth statistic, this is an efficiency concern as opposed to a validity concern. Increasing the number of warmup steps of MCMC iterations might help combat this.

Also, maybe it might be worth paying more attention to features and applying extra transformation (except mean-centering) or even extraction to them. Moreover, the priors can be tested even more accurately, and more exotic distributions could be tried.

The sampling algorithms needs rather large number of iteration to converge, so perhaps changing the architecture of the model (link function, feature selection, etc.) could also be considered in future.

## Things learnt from the data analysis

It was understood that the survival time of patients with advanced lung cancer can be approximated well by Weibull distribution. Further, understanding which institution an individual has been admitted to aids predictive performance. That is why, the model with hierarchical structure, which provides a little different distributions for each institute parameters is better. This was confirmed by ELPD and WAIC parameters, and validated by Pareto $\hat k$ diagnostic plot. 

## Self-reflection and learnings

The group learnt a lot about the applications of MCMC methods to survival analysis, domain specific notation, and vocabulary. The group were also afforded the opportunity to dive deep into more exotic distributions such as the Weibull and Caucy distributions, and to apply these in GLMs. The process of prior ellicitation and model building, including motivating a link function in a non-standard GLM, was very informative. Last but not least, some functions and packages in `R` connected with bayesian statistics were discovered, and used effectively.
